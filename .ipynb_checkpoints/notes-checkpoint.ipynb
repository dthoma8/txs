{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "access to MADW\n",
    "analytics env\n",
    "    don't have data*lockheed has possession\n",
    "    potential kickoff next week\n",
    "    kicking off the training\n",
    "    setting up the sandbox\n",
    "        what analysis\n",
    "        vms\n",
    "        other potential implementations\n",
    "        hosting of vms - here or aws\n",
    "        accessing prod data. source data? etl & pipelining?\n",
    "        shruti is building mlestns\n",
    "        deliverable to lev mafw. need to bring in manpower data, flynig hour data\n",
    "        build recipes around readiness\n",
    "        accessing prod data\n",
    "        if they want free hand text then an extract will need to be created\n",
    "        data vuration piece\n",
    "            need to work directly with their orsas\n",
    "            vertica houses the transformed-curated data. they should not be touching these for analyses\n",
    "        they want to walk through the curation process\n",
    "        migrate these to immuta.\n",
    "        upon completion of the curation this data can be pulled into the data science env.\n",
    "        ato*pii problem\n",
    "        2 mos to iron out data requirements. Shruti heading the agenda\n",
    "        baselining the training for the environemnt. Tailoring the training for the skillset that they have in place\n",
    "        af manpower sme in the works\n",
    "        dmdc manpower data very similar. skill level broken down by afc. gets to air force level detail of maintainers, etc. definining the expertise relatlive to af\n",
    "        **deliverables: dashboards (2). and training**\n",
    "        **unscheduled maintenance the major problem. material availabiity**\n",
    "        **reconstructing these problems to walk them to the root and to a solution**\n",
    "            **create opportunities for other possible soltns**\n",
    "        **already @ the descriptive stage. need to abstract further**\n",
    "            **ranking**\n",
    "    **orientation program for onboarding ds'**\n",
    "    **what is this going to look like at scale**\n",
    "    **what does enabling them to perform their own analysis and reduce reliance on other parties look like?**\n",
    "    **skills asseessment format**\n",
    "        \n",
    "            \n",
    "    \n",
    "security reqs\n",
    "other reqs\n",
    "\n",
    "#### Launch Acts\n",
    "\n",
    "- lattice for af\n",
    "- six month quick turn. end in dec\n",
    "- analytics and assesment shop within the af\n",
    "- aren't the central node, silos \n",
    "- chelseaa churchill, skill assessment\n",
    "- 5th floor touch down point for the orsas\n",
    "- co-delivering so they will be supporting\n",
    "- first phase is to gather ads\n",
    "- customize the madw analytics for their af readiness\n",
    "- adding in manpower data\n",
    "- leading to predictive models to tie in how much spending would cause how much of a boost in readinesss\n",
    "- internal kick off monday afternoon\n",
    "- tackling the new data. curating the data. \n",
    "    - primary focus is to accentuate the data to add treadiness\n",
    "- where is the a9 right now in terms of categorizing readiness\n",
    "- training w/ojt\n",
    "- maturity model tuesday afternoon\n",
    "- chip prior to aug/trevor chan aug-after\n",
    "- technology that the orsas use\n",
    "\n",
    "#### madw\n",
    "\n",
    "- how long to obtain access to data sources?\n",
    "- are we looking to recreate an exact replica of the schema currently in madw?/Is this to flexible to the needs that we are able to extract early on the process?\n",
    "\n",
    "#### outline of technology required\n",
    "\n",
    "- postgresql\n",
    "- \n",
    "\n",
    "#### my understanding\n",
    " \n",
    " AO is out of the things that we have active in our inventory, what is our average availability?\n",
    " Am is out of everything including inactive items in our inventory, what is the average availability?\n",
    " PMAI?\n",
    " \n",
    "**Kick Off Meeting**\n",
    "\n",
    "- tom bundress, tony kravit, carol albright, orsa, kevin/orsa, rivers jenkins/orsa, michael/orsa - personnel training\n",
    "    - aa vision/wrangle data better/industry standards\n",
    "- log reform task?\n",
    "- themus\n",
    "\n",
    "-  interest in predicting where investment could drive avialbity to a greater degree\n",
    "- availability + manpower = potential\n",
    "- \n",
    "- get values out of th eprototype\n",
    "- potential to be where all work is performed\n",
    "- governance layer for different users\n",
    "- data engineering pipelines may be customized\n",
    "- would like to perform work at theetnagon\n",
    "- to show for demos\n",
    "- d3/python/r/tableau\n",
    "- can pull from tehe final prod records hosted in the site\n",
    "- jupyternotbeook/ide/-based vm\n",
    "- want to be able to access the vm from the pentagon\n",
    "- 5-10 orsas\n",
    "- sending people in pairs\n",
    "- a day a week  the rest of the time remote comms\n",
    "    - work rto develop the ontolgies of the data\n",
    "   \n",
    "- data science refresher - try to level set the knowledge amongst the data science team\n",
    "- preference to use their own laptops\n",
    "- understanding the data, sql queries, data frame manipulation, explorations, building models\n",
    "- what are the problems harming readiness\n",
    "\n",
    "- reinvention of the data science workflow and the way that a9 performs analytics and creating a new standard for the rest of the air force to continue to perfom analytics\n",
    "- there is a need for tansparency in the way that the calculations are derived\n",
    "    - we need a configurable feature selector that allows the users to customize what the ccalulation of a emtric sactually si\n",
    "- training to some general competency level\n",
    "- then there is a desire to create pipelines so sthat the processing and the magic can happen faster\n",
    "- currculum dev - who is leading this?\n",
    "- \n",
    "\n",
    "\n",
    "**second meeting**\n",
    "\n",
    "- Chp poc about metric generation\n",
    "- service specific views for the dashbaords\n",
    "\n",
    "- we need to keep track of where a9believes that they are going\n",
    "\n",
    "- diagnostic analysis - creating data that is not there present in the data to create additional viewa\n",
    "- tailor tha maturity model to the capabilities that mean something to the af orsas\n",
    "\n",
    "- this needs to be relevant to the organization desires\n",
    "\n",
    "- orsas do not actually know what data sources they should be workin gwith nor the infromation that they need or could be creating fro this\n",
    "\n",
    "- chip hasa list of adhoc questions that we can mayve potetnially utilize\n",
    "\n",
    "- need to pinpoint the research questons that are necessary\n",
    "\n",
    "- there really needs to be an undestaning developed about the data currelty aviable\n",
    "\n",
    "- illustrate to the orsas and relevant personnel what the feasibility of certain research areas will lead to \n",
    "\n",
    "- understand where they are/inform where they will be/infroma where they can be\n",
    "\n",
    "- understand and illustrate the constraints that twill be asociated with the output and where the orsaa will actually want to be\n",
    "- \n",
    "\n",
    "#### Week 1 Planning\n",
    "\n",
    "6hrs each day/10-3\n",
    "4hrs on Tuesday for MADW Immersion\n",
    "    - This serves as LMIs approach to the readiness question\n",
    "   - allows for the opportunity to get them engaged in how they are tackling readiness\n",
    "   - work w/tech ppl to get the proper tech stuff installed\n",
    "   - helps identify gaps in the dashboard/data \n",
    "   - identify the topics that will constitute the tech stack intorduction - DT\n",
    "   - formal feedback for MADW - DT\n",
    "   - problem statement - unpacking what the project goals are and the plan of attack\n",
    "   - a3/logistics/data strat\n",
    "   - reconcile data silos that are being created\n",
    "   - speed to insight\n",
    "   \n",
    "   * tech conversation - aircraft avaialbility study\n",
    "       * tom / kevin\n",
    "       * A9\n",
    "       * doug/douglas\n",
    "           * leader of the branch that we will be work with\n",
    "           * this is the head of the people that we will be working with\n",
    "           \n",
    "We want a defensible,yet flexible measure for readiness.\n",
    "\n",
    "The flexibility comes in identifying the drivers (features) which also leaves a defensible measure for readiness flexible. How can we normalize an end?\n",
    "\n",
    "From an equipment prospective/readiness is directly proportional to availability percentage. Target availability is 80%. Would this mean that readiness is 1.0 or 0.8?\n",
    "\n",
    "What is th Weapons Systems Health Scorecard?\n",
    "\n",
    "Ariel Lai compiles the Healthscore card\n",
    "SpSLI is super inactive\n",
    "\n",
    "Field/Depot \n",
    "Two different types of readiness\n",
    "Tehre are several different tiers to being in service\n",
    "\n",
    "Are there different systems or priority systems of focus\n",
    "\n",
    "UnitofAN. addnl of action item. status. is it in service/active/etc\n",
    "Cost per day of avialability \n",
    "\n",
    "MC  - PMAI\n",
    "A0 = Inventory/TAI, TAI = \n",
    "\n",
    "Opp ANalysis\n",
    "Swae - opportnity analysis\n",
    "\n",
    "Who cares about analytics in the air force?\n",
    "\n",
    "Work w/Chip to learn some Q's for MADW\n",
    "\n",
    "My scope:\n",
    "\n",
    "Icebreakers at the beginging of the day\n",
    "Rose/THorn.Bud at the end of the day\n",
    "\n",
    "Topic: overviw of the day\n",
    "0 \n",
    "Printer office. right left double door to the printer room. 6east\n",
    "\n",
    "### Session 1\n",
    "\n",
    "#### Intros\n",
    "\n",
    "Kevin\n",
    "Worked fro maircraft readiness perspective\n",
    "\n",
    "tom\n",
    "home brewer\n",
    "ice skates\n",
    "reinvented infrastructure and modernize the data scientist platform to meet\n",
    "\n",
    "doug\n",
    "\n",
    "a9 ari division\n",
    "how to operate in a large data enfirnment improve the undesrtanding in how to leverage the technologies\n",
    "working with the cdo to be able tge tmotion in these things\n",
    "\n",
    "readiness avaialbility anatsiscost anaalysis\n",
    "\n",
    "Ken\n",
    "\n",
    "mathmetician orking aas an orsa, simulations developing simulation models\n",
    "\n",
    "Riv\n",
    "\n",
    "coding experience \n",
    "impact high level decision s\n",
    "\n",
    "matt\n",
    "promming experienc ein r. here to learn\n",
    "\n",
    "mike\n",
    "rp - more personnel modelingside/ri\n",
    "trying to learn more aspects of python specifically as iot relates to the machine learning\n",
    "\n",
    "cara\n",
    "\n",
    "ap r\n",
    "never used python and looking to learn\n",
    "\n",
    "#### Stakeholder Mapping\n",
    "\n",
    "*chief of staff of the af. main customers are higher level\n",
    "\n",
    "Customers\n",
    "    \n",
    "    source of the problem\n",
    "    safmg - work on metrics development ksthe air force deilivering what is supoosed\n",
    "    a5 program sorting. optimization. how do you decide which programs or actions to prioritize. what the rationale is\n",
    "    a1 partner division. rp. personnel division. trend analysis\n",
    "    a3 a lot of collaboration. ops director. decision tools. TRENDS. READIENESS. helping to build a model for readiness. excel based analytics. usually based off a single dataset and work to make it usable generate slides. trying to come away from this process into something more modernized.\n",
    "    a4 - avaialability as it relates to aircragt. maintenance manning. sorting generation\n",
    "    a8. runs airforces program planning process. ~= slt. helps senior leaders decide what get funded. puts together tools to help the formulate the facts needed to do that. cost analysis\n",
    "    ett - enterprise trade tool excel based. buld a tool that eactually uses data rather than relying on smes to generate the data\n",
    "    a6 - risk framework. how should they be thinkin gabout risk. joint staff has a risk format that a9 supported. not realy being supported any more\n",
    "    ^ these guys usually have ery specific questions\n",
    "    csaf/vice chief\n",
    "    a3, a4, a8, a1 for rp\n",
    "    importance on reusable analyses components\n",
    "    customers consume powerpoint. sometimes they get spreadsheet. wrting reports. internal usage on reports more so than external. the cusetomers usually wwould like static charts more so than a writteen report.\n",
    "    a3 is the primary or most frequent customer. meet with every weeek\n",
    "    working to develop a relation ship with a4. [ptemtoa;ly a function of more mature data fuplatform\n",
    "    a4 is usually involved in the decision making of analytics\n",
    "    a9 isn't involved early in the process\n",
    "    usually a8 is brought in when a decision has already been made\n",
    "    if we can demonstrate agility and responsiveness and then theis can be a feeder to bein ginvolved earlier on\n",
    "    getting data is always a problem. some of the customers are dta owners. suborganizations havedata that wont give it to the parent. \n",
    "    a4 is a problem in regarfsfor this\n",
    "    would like infrastructure to be more accessible. \n",
    "    CDO eants to own the entire analytic infrastructure. CDO is reinventing it when there are resoruces in place causing the a9 hairpulling diseases\n",
    "    from immuta left. Institutionalize the process for the air force\n",
    "    left of the db problem. how do we increase accessto the data so that analsis can be performed more frequently\n",
    "    need to know what the cdo is doing so we can informa them what they actually need to be doing\n",
    "    cdo is a barrierbut if they can be shown what needs to be done, potentially they will do it.\n",
    "    \n",
    "Second GROUP\n",
    "\n",
    "    corporate process i s completel yfocussdon the budgetary strycture\n",
    "    how are we going to do more with less\n",
    "    enterprise decisions\n",
    "    policy and plaanning\n",
    "    maybe we can change they wway that we operate to do things better\n",
    "    STRATEGIC decision support\n",
    "    \n",
    "    specific modeling/simulation capability was the original intent for a8\n",
    "    a9r 0 inftstructure readiness piece belongs to doug\n",
    "    \n",
    "    action officers that just need help with a macro\n",
    "    hep me build a spreadsheet that does the following thing\n",
    "    visualization of their prolem\n",
    "    proble discovery\n",
    "    sometime s there is staff aug where the a9 comes in and partners with a specific office to run models nd build things in r\n",
    "   \n",
    "    tactical decision support\n",
    "    \n",
    "    caoc - where we to date with munitions, fuels, e.g. other resources. g iving a quantitiative reuslt for where we are and where we iwill be\n",
    "    modilign and simulation os mission planning. how should we be allocating resources for a given mission. nd building this out a  squadron level\n",
    "   \n",
    "    operational decision support\n",
    "    \n",
    "    pre-aquisition.\n",
    "    \n",
    "    this may cost more but the operational costs will be more\n",
    "    \n",
    "    crisis task force of the month\n",
    "    right now it is readiness\n",
    "    seniro leaders hair set on fie. \n",
    "    everybody gts thrown in a box to figure things out\n",
    "    a9 doesn't usually have the data needed to perform the analysis\n",
    "    usually big fuzzy problem\n",
    "    stop talking about the domain. show me how we are oging tod o it\n",
    "    senior leaders often show up with an idea and expecting a9 to respond on the fly to a givenquestion\n",
    "    more iterative more rapid process\n",
    "    being able to spin up answers alot more quickly is a key prioty. \n",
    "    \n",
    "    \n",
    "concluding notes\n",
    "two si langes\n",
    "crisis/adhoc work\n",
    "sometimes this work may be same level organization that needs help with a specific analysis\n",
    "a9 is the analytic capability but different a's may contract\n",
    "some are starting to stand u an analyticscapbiality through hiringi their own orsas\n",
    "mr. williams the air forces a9\n",
    " \n",
    " \n",
    " interested parties will tend to take work from a9 but are more interested in a9 not overlaping the work that they are looking to accomplish. they are the biggest matchcom a9. they are interested to the extent that a9 is not contracicting or chlegning th eowrk that they are already doing. \n",
    " \n",
    " so a9 needs to interact witht his offie for validation to make sure that they arre not stepping on toes\n",
    " they know specifically bpombers and specific domains\n",
    " \n",
    " a9 job is to decision suppor\n",
    "pre-decisional\n",
    "they ave ased a9 t help define the decision\n",
    "post-decisional\n",
    "they already know the answer and want the a9 stamp of approval\n",
    "    they dont want doube checking off their homework\n",
    "    also they dont trust the a9 to handle this because o f responsiebemess\n",
    "a9 still retains the power of saying that an aswer or decision that is brought to them int correct\n",
    "\n",
    "csccenaio: a8 will come up with astudy. and then it may be non-concurred. sometimes the answer doesn't seem to be substaintieted.\n",
    "\n",
    "meeting with training people with a3\n",
    "used to pushing paper up to higher ups and then allowingit to propagate down as needederather than working directly with a9\n",
    "\n",
    "also pre-decisionalcoming from external companies when the deicsion has already been made and that the contractor  maintain ownership of the data and thereby nota lllowing the a9 to validate the decisions made. \n",
    "\n",
    "at the ops level, they are icentivized to act quickl, rather than cautiously and cccurately\n",
    "culutral tension because the leadershiop want s the answer quickly and people wthat can swer these questions quickly asre susualy reewarded. first one with the right answer usualyl wins\n",
    "\n",
    "working with the functionals to define the readiness\n",
    "mckinsey outlines who should be doing what\n",
    "a4 hould be reaced out to girst. then a3. major moddling efort for taraining tdata of the priority because it s upcoming in the nexy fy.\n",
    "\n",
    "a9 wants theis data loaded in so that tehyc an be performing these analyses. need to brush up the skills so that they can get up to speed\n",
    ".\n",
    "emphassi on learning python\n",
    "need the analytia tool case to be doing this\n",
    "\n",
    "pile up the data, perform feature engingeeering/proide domain expertise to define and measure what readiness is \n",
    "'\n",
    "simulation for sorting generation metrics developed by mckinsey\n",
    "a3 partnereed by mck.\n",
    "a9 is to provide the anayticscaability and the dashboarding\n",
    "the cdo has [rpoted that they can build the entir,e infrastructure stack\n",
    "wants to be able to project//\n",
    "uderstanding how readiness iseven generated to be able indicate what readiness\n",
    "modeling and simulation to accomplsish this\n",
    "loss of undestaningni in what readiness means a3 is the other party involved in taht readiness measn and the a9 will need need to work with a3 to be able to form a R amongst the air force\n",
    "\n",
    "ready.ready for waht. 386? a9 substaintated a number 386. \n",
    "dev partners\n",
    "potential to mbe a mechanism to train other offices in af\n",
    "changing the way that the anakytics operatres\n",
    "\n",
    "\n",
    "Matchcoms\n",
    "\n",
    "AF\n",
    "A9 - Decision Suppport\n",
    "    RP & RI\n",
    "    \n",
    "A3 - readiness/training. \n",
    "rob charlesworth. are we getting the same amount of avialability dollar per maintenance\n",
    "\n",
    "A4 - matinenance//logistic\n",
    "A1 - manpower\n",
    "A8 - cost if you give me this set of resources then we can give you this amount of readiness\n",
    "\n",
    "Sources\n",
    "Avialability\n",
    "Costin data - already curated easy to obtain\n",
    " \n",
    "planned work\n",
    "    \n",
    "    \n",
    "    \n",
    "csaf - decision support.\n",
    "\n",
    "\n",
    "#### Analytics Skill Surrvey\n",
    "\n",
    "#### MADW Orientation\n",
    "\n",
    "is a9 being effective/\n",
    "stanardizing langauage and terminiology to define what effectiveneess. fixing one end\n",
    "alignent causes further issues becaus sometimes the plane is limbo and not actuall in limbo. \n",
    "data is snapshots and not actually real time\n",
    "there are times when the data source where the acutla data thtat should be being pulled in is true in one source but the chjangeshavent propagated to the enxt source\n",
    "\n",
    "are there transactional maintenace data that we should be pulling\n",
    "cls budget execution data is in cafdacswhat availability fro xls platforms\n",
    "how to incentivize data owners to prompt data is open for business\n",
    "were using aftar aftoc for the cost piece\n",
    "is it one for one when it comes to avaialbility and dollar invested. if not what is the rato\n",
    "\n",
    "#### Reflection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Stakeholder Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose Outcomes\n",
    "\n",
    "Average self-rating was *1.979*.\n",
    "\n",
    "*Data Analysis Insights As Inputs*-1.500\n",
    "*Diagnostic Data Analysis*-2.625\n",
    "*Exploratory Data Analysis*-2.625\n",
    "*Longitundinal Data Analysis*-1.250\n",
    "*Predictive Data Analysis*-1.500\n",
    "*Time Series Analysis*-2.375\n",
    "                  \n",
    "### Tech Tools Platform\n",
    "\n",
    "*.NET*-0.125\n",
    "*C*-1.000\n",
    "*C#*-0.375\n",
    "*C++*-1.500\n",
    "*Client Server Relational DBs*-0.750\n",
    "*Cloud-based Computing*-0.625\n",
    "*Data Dashboards*-2.000\n",
    "*Deep Learning Frameworks*-0.375\n",
    "*Desktop Relational DBs*-1.500\n",
    "*Distributed Computing*-0.625\n",
    "*Distributed DBs*-0.125\n",
    "*GPU processing*-0.250\n",
    "*Generating Data Visualizations*-1.375\n",
    "*In memory processing*-0.375\n",
    "*Java*-0.750\n",
    "*Javacsript*-0.250\n",
    "*Julia*-0.125\n",
    "*Lisp/Closure*-0.375\n",
    "*Microservices*-0.125\n",
    "*Multi-threading*-0.375\n",
    "*NoSQL DBs*-0.125\n",
    "*Open Source DB Tools*-2.625\n",
    "*Open Source GIS tools*-0.125\n",
    "*Open Source Network Analysis tools*-0.125\n",
    "*Open source Machine learning tools*-1.000\n",
    "*PHP*-0.125\n",
    "*Perl*-0.250\n",
    "*Proprietary DB Tools*-2.500\n",
    "*Proprietary GIS tools*-0.750\n",
    "*Proprietary Machine learning tools*-1.125\n",
    "*Proprietary Network Analysis tools*-0.000\n",
    "*Python*-1.500\n",
    "*R*-2.250\n",
    "*Ruby/Rails*-0.125\n",
    "*SQL*-0.875\n",
    "*Scala*-0.375\n",
    "*Source Code Management*-1.000\n",
    "*Visual Basic*-1.375\n",
    "\n",
    "### Data Size\n",
    "\n",
    "*Feature Extraction*-1.000\n",
    "*Feature Selection*-1.625\n",
    "*Less Than 10GB*-3.750\n",
    "*More Than 100GB Less Than 1TB*-0.625\n",
    "*More Than 100TB Less Than 1PB*-0.125\n",
    "*More Than 10GB Less Than 100GB*-1.375\n",
    "*More Than 1PB*-0.125\n",
    "*More Than 1TB Less Than 100TB*-0.250\n",
    "\n",
    "### Data Characteristics Storage Mgmt\n",
    "\n",
    "Average self-rating was **\n",
    "\n",
    "*Audio Formats* - 0.375\n",
    "*CSV/ascii* - 1.375\n",
    "*Data Governance* - 0.500\n",
    "*Data Lakes* - 0.625\n",
    "*Data Warehouses* - 0.875\n",
    "*Geospatial Formats* - 0.500\n",
    "*Hierarchical Data Format*-0.000\n",
    "*Image Formats* - 0.750\n",
    "*Javascript Object Notation* - 0.375\n",
    "*Unstructured Text* - 1.125\n",
    "*Video Formats* - 0.625\n",
    "*XML* - 0.250\n",
    "\n",
    "### Analysis Techniques\n",
    "\n",
    "Average self-rating was **\n",
    "\n",
    "*Agent-based* - 0.75\n",
    "*Convolutional Neural Network* - 0.5\n",
    "*Data Engineering* - 1\n",
    "*Decision Tree* - 1.875\n",
    "*Deep Learning* - 0.5\n",
    "*Deep Neural Network* - 0.5\n",
    "*Discrete Event* - 2.375\n",
    "*Extract Transform Load* - 0.75\n",
    "*Feature Engineering* - 1.125\n",
    "*Generate Pseudo Datasets* - 1.5\n",
    "*K-Means Clustering* - 1.375\n",
    "*Microsimulation* - 0.5\n",
    "*Monte Carlo* - 2.375\n",
    "*Natural Language Processing* - 1.5\n",
    "*Supervised Feature Learning* - 0.875\n",
    "*Support Vector Machine* - 1\n",
    "*Systems Dynamics* - 1.250\n",
    "*Unsupervised Feature Learning* - 1.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Purpose Outcomes', 'Tech Tools Platform', 'Data Size',\n",
       "       'Data Characteristics Storage Mgmt', 'Analysis Techniques'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadData().theme.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theme      focus                         \n",
       "Data Size  Feature Extraction                1.000\n",
       "           Feature Selection                 1.625\n",
       "           Less Than 10GB                    3.750\n",
       "           More Than 100GB Less Than 1TB     0.625\n",
       "           More Than 100TB Less Than 1PB     0.125\n",
       "           More Than 10GB Less Than 100GB    1.375\n",
       "           More Than 1PB                     0.125\n",
       "           More Than 1TB Less Than 100TB     0.250\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadData().query(\"theme=='Data Size'\").groupby([\"theme\", \"focus\"]).score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(init_plot(f=\"Purpose Outcomes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    1.979167\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadData().query(\"theme == 'Purpose Outcomes'\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.3.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.3.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.3.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.3.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.3.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from bokeh.io import curdoc\n",
    "import yaml\n",
    "from bokeh.io import show,output_notebook\n",
    "from bokeh.plotting import Column, figure, gridplot, Row\n",
    "from bokeh.themes import Theme\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.models import ColumnDataSource, Select, HoverTool\n",
    "output_notebook()\n",
    "d = {\"Purpose Outcomes\":{\"Exploratory Data Analysis\":[4,3,3,3,3,0,3,2], \n",
    "                         \"Diagnostic Data Analysis\":[4,3,3,4,2,1,2,2], \n",
    "                         \"Predictive Data Analysis\":[1,0,2,2,3,2,1,1], \n",
    "                         \"Time Series Analysis\":[3,1,2,2,3,2,2,4], \n",
    "                         \"Longitundinal Data Analysis\":[3,1,2,1,1,1,1,0], \n",
    "                         \"Data Analysis Insights As Inputs\":[2,2,2,2,3,0,1,0] \n",
    "                        },\n",
    "     \"Tech Tools Platform\":{\"C\":[1,1,1,0,2,3,0,0], \n",
    "                            \"C++\":[1,0,2,3,0,4,0,2], \n",
    "                            \"C#\":[0,0,1,2,0,0,0,0], \n",
    "                            \"Java\":[1,1,2,0,0,2,0,0], \n",
    "                            \"Javacsript\":[1,0,1,0,0,0,0,0], \n",
    "                            \"Julia\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Lisp/Closure\":[0,0,1,1,0,1,0,0], \n",
    "                            \".NET\":[0,0,1,0,0,0,0,0],\n",
    "                            \"Perl\":[0,0,1,0,0,1,0,0], \n",
    "                            \"PHP\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Python\":[1,0,2,2,4,1,1,1], \n",
    "                            \"R\":[1,1,3,4,3,1,3,2], \n",
    "                            \"Ruby/Rails\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Scala\":[0,0,3,0,0,0,0,0], \n",
    "                            \"SQL\":[2,0,2,1,1,1,0,0], \n",
    "                            \"Visual Basic\":[2,2,2,1,2,0,2,0],\n",
    "                            \"Desktop Relational DBs\":[3,2,3,1,1,0,1,1], \n",
    "                            \"Client Server Relational DBs\":[1,0,3,1,1,0,0,0], \n",
    "                            \"NoSQL DBs\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Distributed DBs\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Open Source DB Tools\":[1,1,4,4,4,1,4,2], \n",
    "                            \"Proprietary DB Tools\":[2,2,2,2,3,2,3,4], \n",
    "                            \"Open source Machine learning tools\":[1,0,2,0,3,0,1,1], \n",
    "                            \"Proprietary Machine learning tools\":[2,2,1,1,1,1,1,0],\n",
    "                            \"Open Source Network Analysis tools\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Proprietary Network Analysis tools\":[0,0,0,0,0,0,0,0], \n",
    "                            \"Deep Learning Frameworks\":[0,0,1,0,1,0,1,0],\n",
    "                            \"Source Code Management\": [0,0,2,1,3,0,1,1],\n",
    "                            \"Generating Data Visualizations\":[2,2,2,2,2,0,1,0], \n",
    "                            \"Data Dashboards\":[3,2,2,4,1,2,2,0], \n",
    "                            \"Distributed Computing\":[1,0,1,1,2,0,0,0], \n",
    "                            \"Cloud-based Computing\":[0,0,2,1,1,0,0,1],\n",
    "                            \"Open Source GIS tools\":[0,0,1,0,0,0,0,0], \n",
    "                            \"Proprietary GIS tools\":[0,0,3,1,0,0,0,2], \n",
    "                            \"GPU processing\":[0,0,1,1,0,0,0,0], \n",
    "                            \"In memory processing\":[0,0,1,1,1,0,0,0], \n",
    "                            \"Microservices\":[0,0,1,0,0,0,0,0],\n",
    "                            \"Multi-threading\":[0,0,1,1,0,1,0,0]\n",
    "                           },  \n",
    "     \"Data Size\":{\"Less Than 10GB\":[4,3,4,4,4,3,4,4],\n",
    "                  \"More Than 10GB Less Than 100GB\":[3,2,1,1,2,2,0,0], \n",
    "                  \"More Than 100GB Less Than 1TB\":[2,0,1,1,0,1,0,0], \n",
    "                  \"More Than 1TB Less Than 100TB\":[1,0,1,0,0,0,0,0], \n",
    "                  \"More Than 100TB Less Than 1PB\":[0,0,1,0,0,0,0,0], \n",
    "                  \"More Than 1PB\":[0,0,1,0,0,0,0,0], \n",
    "                  \"Feature Selection\":[1,0,3,3,3,0,3,0], \n",
    "                  \"Feature Extraction\":[1,0,2,1,2,0,2,0]\n",
    "                 }, \n",
    "     \"Data Characteristics Storage Mgmt\":{\"Audio Formats\":[1,0,2,0,0,0,0,0], \n",
    "                                          \"Geospatial Formats\":[0,0,2,0,1,0,0,1], \n",
    "                                          \"Hierarchical Data Format\":[0,0,0,0,0,0,0,0], \n",
    "                                          \"Image Formats\":[1,0,1,0,2,0,0,2],\n",
    "                                          \"Javascript Object Notation\":[0,0,2,0,1,0,0,0], \n",
    "                                          \"CSV/ascii\":[0,0,4,0,4,0,0,3], \n",
    "                                          \"Video Formats\":[1,0,1,0,0,0,3,0], \n",
    "                                          \"XML\":[0,0,2,0,0,0,0,0], \n",
    "                                          \"Unstructured Text\":[1,2,2,1,2,0,1,0],\n",
    "                                          \"Data Warehouses\":[2,0,2,1,2,0,0,0], \n",
    "                                          \"Data Lakes\":[1,0,2,0,2,0,0,0], \n",
    "                                          \"Data Governance\":[1,0,2,0,1,0,0,0]\n",
    "                                         }, \n",
    "     \"Analysis Techniques\":{\"Data Engineering\":[1,0,2,0,3,1,1,0], \n",
    "                            \"Extract Transform Load\":[1,0,2,0,2,1,0,0], \n",
    "                            \"Feature Engineering\":[0,0,2,2,3,0,2,0], \n",
    "                            \"Supervised Feature Learning\":[0,0,2,0,4,0,1,0], \n",
    "                            \"Unsupervised Feature Learning\":[0,0,2,2,3,0,2,0],\n",
    "                            \"Convolutional Neural Network\":[0,0,1,0,1,1,1,0], \n",
    "                            \"Decision Tree\":[2,1,4,1,4,1,2,0], \n",
    "                            \"Deep Learning\":[0,0,1,0,2,0,1,0], \n",
    "                            \"Deep Neural Network\":[0,0,1,0,2,0,1,0], \n",
    "                            \"K-means Clustering\":[1,0,3,1,3,0,2,1], \n",
    "                            \"Support Vector Machine\":[2,0,2,1,3,0,0,0], \n",
    "                            \"Natural Language Processing\":[1,2,2,3,2,1,0,1],\n",
    "                            \"Agent Based\":[3,1,1,0,1,0,0,0], \n",
    "                            \"Discrete Event\":[3,1,2,3,3,2,1,4], \n",
    "                            \"Microsimulation\":[2,0,0,2,0,0,0,0], \n",
    "                            \"Monte Carlo\":[3,1,3,3,3,2,1,3], \n",
    "                            \"Systems Dynamics\":[2,0,3,2,0,0,1,2], \n",
    "                            \"Generate Pseudo Datasets\":[3,1,2,0,3,0,0,3]\n",
    "                           }\n",
    "    }\n",
    "with open(\"skills_data.pkl\", \"wb\") as  f:\n",
    "    pickle.dump(d, f)\n",
    "    \n",
    "def loadData(fname=\"./skills_data.pkl\"):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        data=pickle.load(f)\n",
    "    Order = ['ka', 'db', 'tb', 'md', 'rj', 'kc', 'mb', 'ca']\n",
    "    data=(pd.DataFrame({\"theme\":t,\n",
    "                        \"focus\":f,\n",
    "                        \"score\":v\n",
    "                       } for t in data for f,V in data[t].items() for v in V\n",
    "                      ))\n",
    "    data=data.assign(order=np.tile(np.array(Order),int(len(data)/len(Order))))\n",
    "    return data\n",
    "def formDataView(var=\"theme\",names_var=\"order\"):\n",
    "    data = loadData()\n",
    "    data=data.groupby([var,names_var]).score.mean().reset_index()\n",
    "    uniq_vals=data[names_var].unique().tolist()\n",
    "    filters=data[var].unique().tolist()\n",
    "    return {\"data\":data, \"filter\":filters, \"xaxis\":uniq_vals}\n",
    "def filterData(var=\"theme\", names_var=\"order\", f=None):\n",
    "    obj=formDataView(var=var, names_var=names_var)\n",
    "    if f:\n",
    "        data=obj[\"data\"]\n",
    "        data=data[data[var]==f].reset_index(drop=True)\n",
    "        obj[\"data\"]=data\n",
    "        return obj\n",
    "    else:\n",
    "        return obj\n",
    "def init_plot(var=\"theme\", names_var=\"order\", f=None):\n",
    "    obj=filterData(var=var, names_var=names_var,f=f)\n",
    "    data,filters,xaxis=obj[\"data\"],obj[\"filter\"],obj[\"xaxis\"]\n",
    "    if f:\n",
    "        title=f\n",
    "    else:\n",
    "        title=None\n",
    "    p=figure(x_range=xaxis, title=title)\n",
    "    p.circle(x=jitter(\"order\",width=0.6,range=p.x_range),\n",
    "             y=\"score\",\n",
    "             source=ColumnDataSource(data=data),\n",
    "             alpha=0.6,\n",
    "             size=20,\n",
    "             hover_alpha=0.9\n",
    "            )\n",
    "    p.add_tools(HoverTool(tooltips=[\n",
    "        (\"Name\", \"@order\"),\n",
    "        (\"Score\", \"@score\")\n",
    "    ]))\n",
    "\n",
    "    return p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
